{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%run \"../../../common/0_notebooks_base_setup.py\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZb44IL1YZpc"
   },
   "source": [
    "# Dilema entre el sesgo y la varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RS1Zd1cqYZpe"
   },
   "source": [
    "## Tabla de Contenidos\n",
    "\n",
    "1. <a href=\"#section_intro\">Introducción</a>\n",
    "\n",
    "2. <a href=\"#sesgo_varianza\">Sesgo y varianza</a>\n",
    "- 2.1 <a href=\"#sv_simple\">Un modelo simple</a>\n",
    "- 2.2 <a href=\"#sv_cuadratico\">Un modelo cuadrático</a>\n",
    "- 2.3 <a href=\"#sv_complejo\">Un modelo más complejo</a>\n",
    "- 2.4 <a href=\"#sv_new_data\">Prediciendo datos nuevos: *underfitting* y *overfitting*</a>\n",
    "\n",
    "3. <a href=\"#ttcv\">*Train-test split* y *cross-validation*</a>\n",
    "- 3.1 <a href=\"#ttcv_comparando\">Comparando el ajuste y la generalización de distintos modelos</a>\n",
    "  - 3.1.1 <a href=\"#ttcv_uno\">Modelo de grado 1</a>\n",
    "  - 3.1.2 <a href=\"#ttcv_dos\">Modelo de grado 2</a>\n",
    "  - 3.1.3 <a href=\"#ttcv_diez\">Modelo de grado 10</a>\n",
    "  - 3.1.4 <a href=\"#ttcv_cv\">*Cross-validation*</a>\n",
    "\n",
    "4. <a href=\"#section_resumen\">En resumen</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RS1Zd1cqYZpe"
   },
   "source": [
    "<a id=\"section_intro\"></a>\n",
    "##  Introducción\n",
    "\n",
    "Ya hemos visto dos ejemplos de *machine learning* supervisado: entrenamos un modelo de regresión lineal para estimar las ventas de un producto a partir del gasto destinado a publicitarlo en TV y también construimos un modelo de clasificación para detectar *defaults* de tarjetas de crédito. Hicimos hincapié en que el foco está puedo en la predicción, sobre todo de datos nuevos, de ahí la importancia de hacer una separación de los **conjuntos de entrenamiento y testeo**.\n",
    "\n",
    "En un escenario ideal, un modelo puede predecir correctamente los datos que reservamos para testear, obteniendo una métrica de *performance* considerablemente alta. En esta situación, podemos darnos por satisfechos con el proceso de entrenamiento y proceder con la disponibilización del modelo para su uso productivo. **Ahora bien, en caso de que los resultados no sean los que esperamos... ¿cómo lo resolvemos?** Veremos que hay distintos factores que pueden hacer que un modelo no tenga una buena capacidad predictiva:\n",
    "\n",
    "- Podemos estar usando un **modelo demasiado simple**, que no logra aprender lo suficiente de los datos de entrenamiento y, como consecuencia, tampoco logra predicir muy bien los datos de testeo.\n",
    "- Podemos estar trabajando con un **modelo excesivamente complejo**, que se amolda tanto a los datos que conoce que no logra generalizar a datos desconocidos.\n",
    "- Si el dataset es chico, podemos **no contar con suficientes muestras** para lograr un entrenamiento idóneo.\n",
    "- Tal vez la cantidad de observaciones es suficiente para un buen ajuste a los datos, pero **las *features* no aportan suficiente información** o su representación no es la adecuada.\n",
    "\n",
    "En esta oportunidad, nos concentraremos en los primeros dos puntos. Vamos a comparar el desempeño de un modelo en *train* con su desempeño en *test* para tener una mayor noción acerca de sus capacidades de ajuste a los datos de entrenamiento y de generalización a datos nuevos, respectivamente. Esto nos servirá para introducir un aspecto crucial de *machine learning*: **el dilema entre el sesgo y la varianza**. Cuando hablamos de **sesgo**, estamos pensando en un escenario como el del primer punto, en el que tenemos un **modelo muy simple que subajusta a los datos y por eso no tiene un buen desempeño en ninguno de los conjuntos de datos**. En cambio, cuando hablamos de **varianza**, nos encontramos en una situación como la del segundo punto, en que nuestro **modelo tiene una excesiva flexibilidad que lo lleva a sobreajustar a los datos de entrenamiento pero que no le permite predecir bien los datos de testeo**. Veremos que ambos escenarios traen aparejados inconvenientes que buscaremos evitar, tratando siempre de hallar un **ajuste óptimo** del modelo. Dado que los problemas responden a motivos diferententes, veremos que las estrategias de solución dependerán del tipo de escenario en el que nos encontremos.\n",
    "\n",
    "En esta notebook trabajaremos sobre algunos conceptos fundamentales de *machine learning* supervisado que son constantes independientemente del modelo que estemos entrenando: **sesgo y varianza, subajuste y sobreajuste y validación cruzada**. Veremos qué problemas surgen al trabajar con modelos demasiado simples o demasiado complejos y propondremos una metodología para encontrar la complejidad óptima de un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6DNsn3iYZpj"
   },
   "source": [
    "<a id=\"sesgo_varianza\"></a>\n",
    "## Sesgo y varianza\n",
    "\n",
    "Para ilustrar los conceptos de sesgo y varianza, trabajaremos sobre datos aleatorios que responden a cierta función generadora conocida y ajustaremos a ellos modelos de distinta complejidad. **Por el momento, cuando hablemos de la complejidad de un modelo, estaremos pensando en la cantidad de *features* que incluye**: un modelo con una única *feature* es un modelo más simple que otro con diez *features*, por ejemplo. Veremos que modelos simples que no ajustan lo suficiente a los datos tendrán asociado un alto sesgo, mientras que los modelos muy complejos que sobre ajustan a los datos tendrán asociada una alta varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joSRPXanYZpf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos generando pares $(x, y)$ aleatorios a partir de una función cuadrática que incorpora cierta aleatoriedad y los visualizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9EaJLSUDYZpk"
   },
   "outputs": [],
   "source": [
    "n = 20\n",
    "np.random.seed(10)\n",
    "a = 3\n",
    "b = -1\n",
    "c = 1\n",
    "x = np.linspace(-1, 4, n)\n",
    "y = a*x**2 + b*x + c + np.random.randn(n)*5\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('x');\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/haciendo_foco.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>Los datos son generados por una función cuadrática con la forma<br> $y=ax^2+bx+c+\\epsilon$, donde $\\epsilon$ es una perturbación aleatoria.</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HdwxBhg5YZpn"
   },
   "source": [
    "<a id=\"sv_simple\"></a>\n",
    "### Un modelo simple\n",
    "\n",
    "Comenzaremos ajustando un modelo de regresión lineal simple a estos puntos, que serán nuestros datos de entrenamiento. Seguiremos paso a paso el flujo de trabajo de Scikit-Learn que ya hemos presentado antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7qCGJmOYZpo"
   },
   "outputs": [],
   "source": [
    "# Importamos la clase LinearRegression \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6zQZpArYZpr"
   },
   "outputs": [],
   "source": [
    "# Instanciamos el modelo\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qob-jC-rYZpu"
   },
   "outputs": [],
   "source": [
    "# Ajustamos el modelo a los datos\n",
    "lr.fit(x.reshape(-1,1), y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CbTHLD1DYZpw"
   },
   "source": [
    "Hasta acá, creamos un objeto almacenado en la variable 'lr' que pertenece a la clase `LinearRegression()` que, luego de ejecutar `lr.fit()`, encontró los parámetros del modelo lineal que mejor se ajustan a los datos de entrenamiento. ¿Cuáles son estos parámetros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jxRkUOcqYZp0"
   },
   "outputs": [],
   "source": [
    "# Imprimimos la ordenada al origen\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGP0qMBkYZpx"
   },
   "outputs": [],
   "source": [
    "# Imprimimos la pendiente\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xAQLEuDiYZp3"
   },
   "source": [
    "Con el modelo ya entrenado, podemos hacer predicciones. Digamos que tenemos un nuevo dato cuyo valor de $x$ es $x_n=2.5$. Entonces, la predicción del modelo consiste en calcular $ \\hat{y_n} = \\hat{\\beta_0} + \\hat{\\beta_1} x_{n} $, donde $\\hat{\\beta_0}$ es la ordenada al origen y $\\hat{\\beta_1}$, la pendiente de la recta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "buCAkpk4YZp4"
   },
   "outputs": [],
   "source": [
    "x_n = 2.5\n",
    "y_estimado = lr.intercept_ + lr.coef_[0] * x_n\n",
    "print(y_estimado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_tqENc8YZp7"
   },
   "source": [
    "También podemos usar el método `.predict()` del modelo para hacer el mismo cálculo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ponNBN75YZp8"
   },
   "outputs": [],
   "source": [
    "lr.predict(np.array(x_n, ndmin=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PBtsW-SkYZp-"
   },
   "source": [
    "Y lo podemos aplicar sobre todo el array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6mLdtMZYZp_"
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x.reshape(-1,1))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WnML7ivZYZqC"
   },
   "source": [
    "Veamos cómo se ajusta la recta encontrada a los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tDlJ591IYZqD"
   },
   "outputs": [],
   "source": [
    "plt.plot(x, x*lr.coef_[0]+lr.intercept_,'r')\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('x');\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Cómo se ve este ajuste del modelo a los datos? Considerando la naturaleza cuadrática de la función que generó las observaciones, ¿creés que esta recta explica bien la relación entre $x$ e $y$?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0G7YUacUYZqF"
   },
   "source": [
    "Evaluemos la *performance* de nuestro modelo lineal simple a partir de las métricas que ya conocemos, el **error absoluto medio**, el **error cuadrático medio** y el $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qR-2Mf2YZqJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print('La media del error absoluto es', mae.round(2))\n",
    "print('La media del error cuadrático es', mse.round(2))\n",
    "print('La raíz del error cuadrático medio', rmse.round(2))\n",
    "print('El R2 es', r2.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0czjvfVYZqM"
   },
   "source": [
    "Nuestro modelo simple logra explicar un 71% de la varianza total de $y$. No está mal, pero considerando la naturaleza del problema, es probable que podamos encontrar un modelo mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C0czjvfVYZqM"
   },
   "source": [
    "<a id=\"sv_cuadratico\"></a>\n",
    "### Un modelo cuadrático\n",
    "\n",
    "Dado que los datos fueron generados a partir de una función que tiene un componente cuadrático, veamos ahora qué ocurre cuando incorporamos una *feature* que es el cuadrado de $x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfFdxVzuYZqN"
   },
   "outputs": [],
   "source": [
    "# Generamos un DataFrame con los datos\n",
    "df = pd.DataFrame({'x':x, 'y':y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKH4yfZuYZqP"
   },
   "source": [
    "Ahora creemos una nueva columna que sea $x^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w7FmpSwSYZqQ"
   },
   "outputs": [],
   "source": [
    "df['x2'] = df['x']**2\n",
    "df = df[['x', 'x2', 'y']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCfEiQD3YZqT"
   },
   "source": [
    "Ya que tenemos un *feature* nueva, podemos entrenar otro modelo de regresión lineal que incorpore esta información.\n",
    "\n",
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/haciendo_foco.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>Dado que ahora tenemos más de una <i>feature</i> o variable explicativa, en este caso se trata de un modelo de regresión lineal múltiple en lugar de simple. Ahora, la predicción para cualquier dato $x_n$ viene dada por $ \\hat{y_n} = \\hat{\\beta_0} + \\hat{\\beta_1} x_{n} +  \\hat{\\beta_2} x_{n}^2 $.</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sifAqCtGYZqU"
   },
   "outputs": [],
   "source": [
    "lr2 = LinearRegression()\n",
    "lr2.fit(df[['x', 'x2']], df['y']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuáles son los parámetros aprendidos por el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que ahora el atributo `coef_` es un array con dos elementos, que se correponden con $\\hat{\\beta_1}$ y $\\hat{\\beta_2}$, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8evKIj8YZqY"
   },
   "source": [
    "Con este otro modelo ya entrenado, podemos hacer nuevas predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwFJa8iOYZqa"
   },
   "outputs": [],
   "source": [
    "y_pred_2 = lr2.predict(df[['x', 'x2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualicemos la nueva curva de ajuste a los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y_pred_2, 'r')\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel('x');\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Se ve mucho mejor! Parecería que esta nueva variable explicativa, $x^2$, le otorga una mayor flexibilidad al modelo lineal que le permite aprender mejor qué relación hay entre las *features* y el *target*. Veamos si las métricas de evaluación respaldan esta intuición visual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sv6TiVPJYZqe"
   },
   "outputs": [],
   "source": [
    "mae_2 = mean_absolute_error(y, y_pred_2)\n",
    "mse_2 = mean_squared_error(y, y_pred_2)\n",
    "rmse_2 = np.sqrt(mse)\n",
    "r2_2 = r2_score(y, y_pred_2)\n",
    "\n",
    "print('La media del error absoluto es', mae_2.round(2))\n",
    "print('La media del error cuadrático es', mse_2.round(2))\n",
    "print('La raíz del error cuadrático medio', rmse_2.round(2))\n",
    "print('El R2 es', r2_2.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTCZWFEJYZqi"
   },
   "source": [
    "¡Excelente! Vemos que todas las métricas mejoraron considerablemente agregando tan sólo una nueva *feature*. Pero entonces... ¿por qué detenernos en un $R^2$ del 0.91? Si seguimos agregando *features*, tal vez podamos darle todavía más flexibilidad al modelo y continuar mejorando las métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTCZWFEJYZqi"
   },
   "source": [
    "<a id=\"sv_complejo\"></a>\n",
    "### Un modelo más complejo\n",
    "\n",
    "Seamos ambiciosos e incorporemos más *features* polinómicas hasta el grado 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AuaTghb-YZqj"
   },
   "outputs": [],
   "source": [
    "for i in range(3,11):\n",
    "    df['x{}'.format(i)] = df['x']**i # El método .format() nos permite darle un formato variable a un string\n",
    "                                     # En este caso, el contenido de {} varía en cada iteración de acuerdo al valor de i\n",
    "\n",
    "df = df[['x'] + ['x{}'.format(i) for i in range(2,11)] + ['y']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIEXas9AYZql"
   },
   "source": [
    "Ahora que tenemos el dataset con las nuevas *features* polinómicas, volvamos a entrenar un nuevo modelo y calcular las métricas de evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIUQI0caYZqm"
   },
   "outputs": [],
   "source": [
    "lr10 = LinearRegression()\n",
    "lr10.fit(df.drop('y', axis=1), df['y']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jGAzVzUsYZqo"
   },
   "source": [
    "Veamos los parámetros del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7u0E7xFLYZqp"
   },
   "outputs": [],
   "source": [
    "lr10.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uKnhgSqNYZqr"
   },
   "outputs": [],
   "source": [
    "lr10.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utFYoRPOYZqt"
   },
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿A qué se debe que observemos un array de 10 coeficientes?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzU8WDoNYZqu"
   },
   "source": [
    "Ya estamos listos para hacer predicciones y evaluar la *performance* del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHpnvtAzYZqu"
   },
   "outputs": [],
   "source": [
    "y_pred_10 = lr10.predict(df.drop(columns=['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y_pred_10, 'r')\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel('x');\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yGgpmclYZqw"
   },
   "outputs": [],
   "source": [
    "mae_10 = mean_absolute_error(y, y_pred_10)\n",
    "mse_10 = mean_squared_error(y, y_pred_10)\n",
    "rmse_10 = np.sqrt(mse)\n",
    "r2_10 = r2_score(y, y_pred_10)\n",
    "\n",
    "print('La media del error absoluto es', mae_10.round(2))\n",
    "print('La media del error cuadrático es', mse_10.round(2))\n",
    "print('La raíz del error cuadrático medio', rmse_10.round(2))\n",
    "print('El R2 es', r2_10.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJ10S6zvdRba"
   },
   "source": [
    "¡Seguimos mejorando! Tenemos un $R^2$ altísimo y los errores son cada vez más bajos.\n",
    "\n",
    "Para poder comparar visualmente los modelos explorados, generamos un gráfico que representa los distintos ajustes obtenidos de acuerdo al grado del polinomio de cada uno de los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IrNECOomYZrI"
   },
   "outputs": [],
   "source": [
    "# Generamos un eje para graficar las curvas\n",
    "ejex = np.linspace(-2,8, 100)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15,5))\n",
    "fig.suptitle('Comparación de modelos', fontsize=18)\n",
    "\n",
    "# Ploteamos los datos\n",
    "for axes in ax:\n",
    "    axes.scatter(x, y)\n",
    "    axes.set_xlim([x.min()-1, x.max()+1])\n",
    "    axes.set_ylim([y.min()-1, y.max()+1])\n",
    "    axes.set_xlabel('x', fontsize=15)\n",
    "    axes.set_ylabel('y', fontsize=15)\n",
    "    \n",
    "# Modelo de grado 1\n",
    "curva1 = lr.predict(ejex.reshape(-1,1))\n",
    "ax[0].plot(ejex, curva1, 'r')\n",
    "ax[0].set_title('Grado 1', fontsize=10)\n",
    "\n",
    "# Modelo de grado 2\n",
    "curva2 = lr2.predict(np.vander(ejex, 3, increasing=True)[:,1:])\n",
    "ax[1].plot(ejex, curva2, 'g')\n",
    "ax[1].set_title('Grado 2', fontsize=10)\n",
    "\n",
    "# Modelo de grado 10\n",
    "curva10 = lr10.predict(np.vander(ejex, 11, increasing=True)[:,1:])\n",
    "ax[2].plot(ejex, curva10, 'c')\n",
    "ax[2].set_title('Grado 10', fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TgZ1a_MovKUV"
   },
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Qué observamos en estos gráficos? ¿Cuál de los tres modelos parecería describir mejor la naturaleza de los datos?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ncMbHIXiYZqy"
   },
   "source": [
    "<a id=\"sv_new_data\"></a>\n",
    "### Prediciendo datos nuevos: *underfitting* y *overfitting*\n",
    "\n",
    "El objetivo de entrenar modelos de *machine learning* supervisado es poder encontrar las reglas o las relaciones intrínsecas de los datos que nos permitan hacer predicciones de la variable *target* a partir de los valores de las *features*. Por eso, será de interés conocer cómo se comportará el modelo cuando hagamos predicciones con datos que **no fueron usados durante el entrenamiento**.\n",
    "\n",
    "A continuación, generamos datos nuevos (utilizando la misma función que usamos antes) para poder evaluar cuán bien predice estos datos nuevos cada uno de los modelos que tenemos entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6gI3Zz9YZqz"
   },
   "outputs": [],
   "source": [
    "n = 20\n",
    "x_new = np.linspace(2, 6, n)\n",
    "y_new = a*x_new**2 + b*x_new + c + np.random.randn(n)*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0Kpx4jWYZq1"
   },
   "source": [
    "Verifiquemos que los datos nuevos sigan la misma función que los originales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2q6S-VoYZq2"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.scatter(x_new, y_new);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7vVJgffYZq4"
   },
   "source": [
    "Ahora, debemos repetir con los datos nuevos el mismo proceso de generación de *features* o *feature engineering* que hicimos para los datos de entrenamiento. En nuestro caso, esto consiste en generar las mismas potencias de $x$. Probaremos el modelo de orden 10, ya que fue el que mejor pudo ajustarse a los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "soAm-G5XYZq5"
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame({'x':x_new, 'y':y_new})\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2DpIo4AhYZq7"
   },
   "outputs": [],
   "source": [
    "for i in range(2,11):\n",
    "    df_new['x{}'.format(i)] = df_new['x']**i\n",
    "    \n",
    "df_new = df_new[['x'] + ['x{}'.format(i) for i in range(2,11)] + ['y']]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnHWoLk9YZq9"
   },
   "source": [
    "Ya tenemos los datos listos para que el modelo los pueda utilizar. Hagamos las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1SuIeXNrYZq-"
   },
   "outputs": [],
   "source": [
    "y_pred_new = lr10.predict(df_new.drop(columns=['y']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QIQFTMWjYZrA"
   },
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Qué hubiera pasado si no generábamos las potencias e intentábamos predecir sólo con $x$?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNw0rCJbYZrC"
   },
   "source": [
    "Evaluemos el desempeño del modelo sobre los datos nuevos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7mAgPyefYZrD"
   },
   "outputs": [],
   "source": [
    "mae_new = mean_absolute_error(y_new, y_pred_new)\n",
    "mse_new = mean_squared_error(y_new, y_pred_new)\n",
    "rmse_new = np.sqrt(mse)\n",
    "r2_new = r2_score(y_new, y_pred_new)\n",
    "\n",
    "print('La media del error absoluto es', mae_new.round(2))\n",
    "print('La media del error cuadrático es', mse_new.round(2))\n",
    "print('La raíz del error cuadrático medio', rmse_new.round(2))\n",
    "print('El R2 es', r2_new.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIP_8k8IYZrF"
   },
   "source": [
    "Hmmm... ¿Qué pasó? **Pasamos de un $R^2$ de 0.96 a uno negativo con el modelo de grado 10**. Teniendo en cuenta que siempre buscamos obtener un $R^2$ lo más cercano a 1 posible, **un $R^2$ negativo nos da la pauta de que el modelo está prediciendo considerablemente mal estos datos nuevos**.\n",
    "\n",
    "Analicemos qué está pasando e identifiquemos el problema. Grafiquemos las curvas de los distintos modelos y veamos cómo se aproxima cada una de ellas a los datos nuevos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwGQFi-gYZrP"
   },
   "outputs": [],
   "source": [
    "ejex = np.linspace(-2,8, 100)\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "# Ploteamos los datos\n",
    "plt.scatter(x, y)\n",
    "plt.scatter(x_new, y_new)\n",
    "\n",
    "# Modelo de grado 1\n",
    "curva1 = lr.predict(ejex.reshape(-1,1))\n",
    "plt.plot(ejex, curva1, 'r')\n",
    "\n",
    "# Modelo de grado 1\n",
    "curva2 = lr2.predict(np.vander(ejex, 3, increasing=True)[:,1:])\n",
    "plt.plot(ejex, curva2, 'g')\n",
    "\n",
    "# Modelo de grado 10\n",
    "curva10 = lr10.predict(np.vander(ejex, 11, increasing=True)[:,1:])\n",
    "\n",
    "plt.plot(ejex, curva10, 'c')\n",
    "plt.xlim([x.min()-1, x_new.max()+1])\n",
    "plt.ylim([y.min()-1, y_new.max()+1])\n",
    "plt.legend(['Grado 1', 'Grado 2', 'Grado 10', 'Datos de entrenamiento', 'Datos nuevos']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DN0bFBx1YZrT"
   },
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/haciendo_foco.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label>El modelo de grado 1 busca ajustar una recta a datos que provienen de una función más bien cuadrática, por lo que no llega a captar la verdadera naturaleza de los datos. Por esto, decimos que el modelo es \"demasiado simple\", con una <i>performance</i> relativamente mala tanto en el set de entrenamiento como sobre los datos nuevos. Esto es lo que se conoce como <i><b>underfitting</b></i> o <b>subajuste</b>.\n",
    "<br><br>\n",
    "El modelo de grado 10, en cambio, es \"demasiado complejo\" y logra ajustarse casi a la perfección a este set de datos en particular, por lo que pierde capacidad de generalización y, al encontrarse con datos nuevos, tiene una <i>performance</i> mala y las métricas empeoran. Esto es lo que se conoce como <i><b>overfitting</b></i> o <b>sobreajuste</b>.\n",
    "<br><br>\n",
    "Por su parte, el modelo de grado 2 parecería ser el que mejor representa la estructura intrínseca de los datos, teniendo la suficiente flexibilidad como para ajustarse correctamente al set de entrenamiento y al mismo tiempo generalizar adecuadamente a datos nuevos.</label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BIawVXH6YZrU"
   },
   "source": [
    "**¿Cómo podemos identificar cuál es la complejidad correcta de un modelo para nuestro problema?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eu19TmYgYZrX"
   },
   "source": [
    "<a id='ttcv'></a>\n",
    "## Train-test split y cross-validation\n",
    "\n",
    "**La metodología que se utiliza para comparar diferentes modelos y evaluar cuál de ellos se desempeña mejor consiste en reservar una porción de los datos para conocer la capacidad de generalización de los distintos modelos**. Esto responde a la división de los datos en un *training set* y un *testing set* que ya hemos presentado en la notebook de introducción a *machine learning*.\n",
    "\n",
    "Si entrenamos el modelo con un set de datos y luego lo evaluamos con datos distintos, podemos asumir que éste será el desempeño de predicción sobre datos provenientes de la misma distribución, por más que no hayan sido incluidos en el set de entrenamiento.\n",
    "\n",
    "Vamos a reutilizar todos los datos que generamos hasta aquí y aplicar esta metodología para encontrar el grado óptimo del modelo para que se ajuste de la manera correcta, es decir, **evitando tanto el subajuste como el sobreajuste**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "doHonIpiYZrY"
   },
   "outputs": [],
   "source": [
    "# Concatenamos las tablas con los distintos datos generados\n",
    "data = pd.concat([df, df_new], axis=0).reset_index(drop=True)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BX7mJLqaYZrg"
   },
   "outputs": [],
   "source": [
    "# Importamos la función de Scikit-Learn para hacer el split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SD55R3KqYZri"
   },
   "source": [
    "Esta función retornará 4 sets diferentes (2 pares):\n",
    "- $X$ de entrenamiento\n",
    "- $y$ de entrenamiento\n",
    "- $X$ de testeo\n",
    "- $y$ de testeo\n",
    "\n",
    "Usaremos $X$ e $y$ de entrenamiento para ajustar distintos modelos (`.fit(X_train, y_train)`) y luego usaremos $X$ de testeo para hacer nuevas predicciones (`.predict(X_test)`). Vamos a utilizar la métrica del $R^2$ para evaluar la *performance* de cada modelo, tanto sobre *train* como sobre *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cfe29VpYZrl"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['y']), df['y'], random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hdxukRRYZrt"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fPzHAmsYZrv"
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P4oJrdy1YZrx"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6C1CS6daYZr0"
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vowsSBAAYZr1"
   },
   "source": [
    "<a id='ttcv_comparando'></a>\n",
    "### Comparando el ajuste y la generalización de distintos modelos\n",
    "\n",
    "Con los datos ya separados, procedemos a entrenar los distintos modelos sólo con los datos de entrenamiento y analizar cómo se desempeñan en cada uno de los conjuntos, el de entrenamiento y el de testeo. Comparando estos valores podremos conocer el nivel de ajuste y la capacidad de generalización de cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ttcv_uno'></a>\n",
    "#### Modelo de grado 1\n",
    "\n",
    "Nuestro primer modelo es una regresión lineal simple, cuya única *feature* es $x$ (grado 1 del polinomio)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f2VhqiLYZr2"
   },
   "outputs": [],
   "source": [
    "# Utilizamos sólo x para entrenar\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train[['x']], y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHdHhaInYZr3"
   },
   "source": [
    "Con el modelo ajustado, podemos hacer predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UIO8CDNYZr4"
   },
   "outputs": [],
   "source": [
    "y_pred_train = lr.predict(X_train[['x']])\n",
    "y_pred_test = lr.predict(X_test[['x']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4NBorHHYZr6"
   },
   "source": [
    "Y calular métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUfClsmyYZr6"
   },
   "outputs": [],
   "source": [
    "print('El R2 de entrenamiento del modelo de grado 1 es', r2_score(y_train, y_pred_train).round(2))\n",
    "print('El R2 de testeo del modelo de grado 1 es', r2_score(y_test, y_pred_test).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0SfszyMKYZr8"
   },
   "source": [
    "El modelo simple presenta un $R^2$ relativamente bajo tanto en *train* como en *test*. **Éste suele ser un claro signo de sesgo o subajuste**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ttcv_dos'></a>\n",
    "#### Modelo de grado 2\n",
    "\n",
    "Nuestro segundo modelo es una regresión lineal múltiple, que incorpora $x^2$ como variable explicativa (grado 2 del polinomio)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wv132VJ0YZr9"
   },
   "outputs": [],
   "source": [
    "# Utilizamos x y x al cuadrado para entrenar\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(X_train[['x', 'x2']], y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "87hcGmfFYZr_"
   },
   "source": [
    "Predecimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHdHwKLeYZr_"
   },
   "outputs": [],
   "source": [
    "y_pred_train_2 = lr2.predict(X_train[['x', 'x2']])\n",
    "y_pred_test_2 = lr2.predict(X_test[['x', 'x2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbN3eW71YZsB"
   },
   "source": [
    "Y evaluamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fe1M6ETzYZsB"
   },
   "outputs": [],
   "source": [
    "print('El R2 de entrenamiento del modelo de grado 2 es', r2_score(y_train, y_pred_train_2).round(2))\n",
    "print('El R2 de testeo del modelo de grado 2 es', r2_score(y_test, y_pred_test_2).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTq3zzwjYZsG"
   },
   "source": [
    "Usando un modelo cuadrático, mejoraron considerablemente ambas métricas. ¡Este modelo, incluso, predice mejor los datos desconocidos que los que se usaron para entrenarlo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ttcv_diez'></a>\n",
    "#### Modelo de grado 10\n",
    "\n",
    "Nuestro tercer modelo explorado es otra regresión lineal múltiple, que incorpora 10 grados del polinomio como *features*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wv132VJ0YZr9"
   },
   "outputs": [],
   "source": [
    "# Utilizamos todas las variables para entrenar\n",
    "lr10 = LinearRegression()\n",
    "lr10.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "87hcGmfFYZr_"
   },
   "source": [
    "Predecimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHdHwKLeYZr_"
   },
   "outputs": [],
   "source": [
    "y_pred_train_10 = lr10.predict(X_train)\n",
    "y_pred_test_10 = lr10.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbN3eW71YZsB"
   },
   "source": [
    "Y evaluamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fe1M6ETzYZsB"
   },
   "outputs": [],
   "source": [
    "print('El R2 de entrenamiento del modelo de grado 10 es', r2_score(y_train, y_pred_train_10).round(2))\n",
    "print('El R2 de testeo del modelo de grado 10 es', r2_score(y_test, y_pred_test_10).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo ajusta casi a la perfección a los datos de entrenamiento pero tiene un pésimo desempeño cuando predice datos nuevos, incluso peor que aquel propio del modelo simple. **Una buena métrica de entrenamiento y una mala métrica de testeo es un síntoma claro de varianza o sobreajuste**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwxemo3aYZsK"
   },
   "source": [
    "De este análisis surge la duda de **cuál es la complejidad óptima del modelo**, el mejor balance entre subajuste y sobreajuste. A continuación, entrenamos varios modelos incrementando en cada iteración su nivel de complejidad y evaluamos la *performance* sobre *train* y *test*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M6Lj9Vf4YZsL"
   },
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    lr.fit(X_train.iloc[:,:i+1], y_train)\n",
    "    y_pred_train = lr.predict(X_train.iloc[:,:i+1])\n",
    "    y_pred_test = lr.predict(X_test.iloc[:,:i+1])\n",
    "    train_scores.append(r2_score(y_train, y_pred_train))\n",
    "    test_scores.append(r2_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxydA0TdgWTW"
   },
   "source": [
    "Representemos cómo varía el $R^2$ en el set de entrenamiento y en el set de testeo en función de la complejidad del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuGk-JFBYZsR"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(list(range(1,X_train.shape[1]+1)),train_scores)\n",
    "plt.plot(list(range(1,X_train.shape[1]+1)),test_scores)\n",
    "plt.legend([f'$R^2$ de entrenamiento', '$R^2$ de testeo'])\n",
    "plt.title('$R^2$',fontdict=dict(fontsize=18))\n",
    "plt.xlabel('Grado del polinomio (complejidad del modelo)', fontdict=dict(fontsize=15))\n",
    "plt.ylabel(f'$R^2$ Score', fontdict=dict(fontsize=15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTM1vY_lYZsU"
   },
   "source": [
    "Vemos que **al aumentar la complejidad del modelo, el *score* de entrenamiento (representado por la línea azul) siempre mejora**. Esto significa que modelos más complejos tienen **mayor capacidad de ajustarse a los datos de entrenamiento**.\n",
    "\n",
    "Sin embargo, lo que más nos interesa es evaluar qué ocurre cuando predecimos datos nuevos, y por eso **resulta más importante analizar el comportamiento de la curva de *score* de testeo (línea naranja)**. En este caso, observamos que al inicio el $R^2$ de *test* mejora al incrementar el grado del polinomio, pero **a partir del grado 6, la capacidad de generalización cae y la brecha con respecto al *score* de entrenamiento se agranda considerablemente**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCup8YK6YZsU"
   },
   "outputs": [],
   "source": [
    "# El mejor score de testeo es...\n",
    "max(test_scores).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpD-KC7KYZsX"
   },
   "outputs": [],
   "source": [
    "# ... y ocurre para el grado...\n",
    "test_scores.index(max(test_scores)) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿No es llamativo que el mejor <i>score</i> se dé en grado 3 cuando nuestros datos fueron generados por una función de grado 2?<br> Estos resultados, ¿no estarán afectados por la aleatoriedad propia del proceso del <i>train-test split</i>?<br> ¿Cómo podemos darle mayor robustez a este análisis?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvwkLZgsYZsZ"
   },
   "source": [
    "<a id='ttcv_cv'></a>\n",
    "### Cross-validation\n",
    "\n",
    "El procedimiento que acabamos de realizar dividiendo el dataset entre un set de entrenamiento y otro de testeo es un caso particular del método de validación cruzada o *cross-validation* en inglés. Cuando hacemos validación cruzada, **armamos múltiples sets de entrenamiento y validación a partir de un mismo conjunto de datos de entrenamiento**, de forma tal de poder realizar varias pruebas sobre distintos datos desconocidos por el modelo y así tener una mejor noción acerca de su capacidad de generalización.\n",
    "\n",
    "<img src=\"img/3-fold-CV.png\" align=\"center\"/>\n",
    "<div class='epigraph' align=\"center\"><i>3-fold cross validation</i></div><br>\n",
    "\n",
    "**Este esquema ilustra una estrategia de *cross validation* con 3 particiones o *folds*. Tomamos el dataset de entrenamiento y lo dividimos en tres partes de igual tamaño. En cada prueba, entrenamos con 2/3 de los datos y validamos con las observaciones restantes. Lo importante es que, prueba a prueba, los datos de entrenamiento no son siempre idénticos y los datos de validación nunca se repiten, de ahí la idea de \"validación cruzada\".**\n",
    "\n",
    "Realizando múltiples *folds* le damos más robustez estadística al análisis ya que promediamos varios resultados con distintos sets de entrenamiento y validación. En general, trabajamos con 3, 5 o 10 *folds* de validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TyX-MUkUYZsZ"
   },
   "source": [
    "La función `cross_val_score()` de Scikit-Learn nos permite implementar este método sin tener que programarlo a mano. Veamos cómo funciona:\n",
    "\n",
    "```\n",
    "sklearn.model_selection.cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv=’warn’, n_jobs=None, verbose=0, fit_params=None, pre_dispatch=‘2*n_jobs’, error_score=’raise-deprecating’)\n",
    "```\n",
    "\n",
    "Concentrémonos en los argumentos `estimator`, `X`, `y` y `cv`:\n",
    "- `estimator` recibe el estimador que vamos a entrenar. En otras palabras, el objeto que contiene el modelo.\n",
    "- `X` e `y` son los datos que usaremos para el entrenamiento (X_train e y_train).\n",
    "- `cv` es la cantidad de *folds* que queremos realizar.\n",
    "\n",
    "Ejecutemos la función con estos parámetros y veamos qué sucede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfdvKiziYZsc"
   },
   "outputs": [],
   "source": [
    "# Importamos la función cross_val_score del módulo de selección de modelos\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# La ejecutamos indicando como estimador una regresión lineal, especificando el set de train y cuántos folds queremos\n",
    "cross_val_score(estimator=LinearRegression(), X=X_train, y=y_train, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado del método es un array que contiene tantos elementos como *folds* hayamos elegido para trabajar. **Cada valor indica el *score* que se obtuvo sobre el set de validación de una prueba en particular**. Como se trata de un problema de regresión, el *score* por defecto es el $R^2$, pero podemos elegir otras métricas variando el argumento `scoring` de la función.\n",
    "\n",
    "Sobre estos resultados, **podemos calcular un *score* promedio de validación cruzada**, el cual nos dará una idea más clara acerca de cómo performa un modelo de una cierta complejidad sobre distintos datos nuevos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(estimator=LinearRegression(), X=X_train, y=y_train, cv=3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También, podemos calcular alguna medida de dispersión, como el desvío estándar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(estimator=LinearRegression(), X=X_train, y=y_train, cv=3).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repitamos ahora el ejercicio anterior de iterar sobre los distintos grados posibles del polinomio, esta vez haciendo validación cruzada y calculando la media de los *scores* obtenidos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_mean = []\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    estimator = LinearRegression()\n",
    "    cv_score = cross_val_score(estimator, X_train.iloc[:, :i+1], y_train, cv=3)\n",
    "    cv_scores_mean.append(cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCup8YK6YZsU"
   },
   "outputs": [],
   "source": [
    "# El mejor score promedio de validación cruzada es...\n",
    "max(cv_scores_mean).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpD-KC7KYZsX"
   },
   "outputs": [],
   "source": [
    "# ... y ocurre para el grado...\n",
    "cv_scores_mean.index(max(cv_scores_mean)) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I7N9DD8sYZsf"
   },
   "source": [
    "Luego de realizar múltiples pruebas siguiendo la estrategia de validación cruzada, **identificamos que el modelo que mejores resultados obtiene en promedio es aquel de grado 2**, tal como era de esperar considerando la naturaleza de los datos con los que estamos trabajando.\n",
    "\n",
    "**Siempre que deseemos identificar cuál el el grado de complejidad o la configuración óptima de un modelo, será importante realizar diversas pruebas de *cross validation* para contar con resultados robustos que nos ayuden a seleccionar el mejor modelo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KUmqBMHqwtkg"
   },
   "source": [
    "<a class=\"anchor\" id=\"section_resumen\"></a>\n",
    "## En resumen\n",
    "\n",
    "En esta notebook, introdujimos algunos de los conceptos esenciales de *machine learning*: **sesgo y varianza, *underfitting* y *overfitting* y *cross-validation***.\n",
    "<br>\n",
    "\n",
    "<div id=\"caja9\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/kit_de_salida.png\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b> - Modelos muy simples subajustan a los datos, es decir, no tienen la capacidad de aprender correctamente la relación entre las <i>features</i> y el <i>target</i>. Esto hace que tengan alto sesgo y resultados relativamente malos, tanto en el set de entrenamiento como en el de testeo.<br><br>\n",
    "                                                 - Por su parte, modelos muy complejos tienen una excesiva flexibilidad, la cual les permite aprender con sumo detalle la relación entre las <i>features</i> y el <i>target</i> al sobreajustar a los datos. Como contracara, estos modelos tienen alta varianza, que se evidencia cuando se contrastan muy buenos resultados en el set de entrenamiento con muy bajos rendimientos en el de testeo.<br><br>\n",
    "                                                 - <i>Cross-validation</i> es una estrategia que consiste en iterar sobre múltiples sets de entrenamiento y validación a partir de un mismo conjunto de datos de entrenamiento, de forma tal de poder realizar varias pruebas sobre distintos datos desconocidos por el modelo y así tener una mejor noción acerca de su capacidad media de generalización. Las pruebas de validación cruzada dotan de mayor robustez estadística a la evaluación de modelos y serán un paso importante de nuestros análisis siempre que deseemos seleccionar aquel modelo que mejor <i>performance</i> tiene.\n",
    "      </b></label></div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "9.1 Intro a ML II.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
